{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Анализ рентгеновских транзиентов СРГ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearnex import patch_sklearn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Charts configurations\n",
    "np.set_printoptions(precision=3)\n",
    "sns.set('talk', 'whitegrid', 'deep', font_scale=1.0,\n",
    "        rc={\"lines.linewidth\": 2, 'grid.linestyle': '--'})\n",
    "pd.set_option('display.max_rows', 400, 'display.max_columns', None, 'display.max_colwidth', 100)\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "# Sklearn acceleration\n",
    "patch_sklearn()\n",
    "\n",
    "\n",
    "# Enums\n",
    "TRANSIENT_SURVEY = Enum(\"TRANSIENT_SURVEY\",\n",
    "                        [\"NONE\", \"eXVAR\", \"TDEs2\", \"FDS4\", \"TDEs4\", \"QPE\", \"eXVAGN3\", \"TDEs5\", \"TDEs2r7\"])\n",
    "TRANSIENT_CLASS = Enum(\"TRANSIENT_CLASS\", [\"NONE\", \"TDE\", \"QSO\"])\n",
    "\n",
    "\n",
    "# Paths\n",
    "ASSEMBLED_DATA_PATH = Path(\"assembled_data/\")\n",
    "SRG_DATA_PATH = Path(\"srg_data/\")\n",
    "TRITON_DATA_PATH = Path(\"triton_data/\")\n",
    "\n",
    "\n",
    "ArrayOrSeries = np.ndarray or pd.Series\n",
    "\n",
    "\n",
    "class Preconditions:\n",
    "    \"\"\"Класс со статичными методами для проверки условий.\n",
    "\n",
    "    Если условие не выполняется, выбрасывается исключение ValueError\n",
    "    с заданным сообщением.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def check(condition: bool, message: str):\n",
    "        if not condition:\n",
    "            raise ValueError(message)\n",
    "\n",
    "    @staticmethod\n",
    "    def check_pre(precondition: bool, condition: bool, message: str):\n",
    "        if not precondition:\n",
    "            return\n",
    "\n",
    "        Preconditions.check(condition, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Подготовка данных\n",
    "\n",
    "Чтение данных из системы разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mag_ab_from_flux_nanomagies(flux):\n",
    "    return 22.5 - 2.5 * np.log10(flux)\n",
    "\n",
    "\n",
    "def mag_ab_from_flux_jy(flux):\n",
    "    return -2.5 * np.log10(flux / 3631)\n",
    "\n",
    "\n",
    "def asinhmag_dm(flux: ArrayOrSeries, *, flux_err: ArrayOrSeries = None,\n",
    "                flux_ivar: ArrayOrSeries = None, dm: float = 0):\n",
    "    \"\"\"Calculate asinh magnitude with dm shift from fluxes and errors or ivars.\n",
    "\n",
    "    :param flux: flux [nanomaggies]\n",
    "    :param flux_ivar: inverse variance of flux [1/nanomaggies**2]\n",
    "    :param flux_err: flux error [nanomaggies]\n",
    "    :param dm: magnitude shift\n",
    "\n",
    "    :return: caclulated magnitudes\n",
    "    \"\"\"\n",
    "    Preconditions.check((flux_err is not None) ^ (flux_ivar is not None), 'Specify only flux_err or flux_ivar.')\n",
    "\n",
    "    f = flux / 1e9 * np.power(10, 0.4 * dm)\n",
    "    if flux_ivar is not None:\n",
    "        b = np.power(flux_ivar, -0.5) / 1e9 * np.power(10, 0.4 * dm)\n",
    "    else:\n",
    "        b = flux_err / 1e9 * np.power(10, 0.4 * dm)\n",
    "\n",
    "    f, b = f.astype(np.float64), b.astype(np.float64)  # otherwise type error like\n",
    "    # TypeError: loop of ufunc does not support argument 0\n",
    "    # of type numpy.float64 which has no callable arcsinh method\n",
    "\n",
    "    return (np.arcsinh(f / (2 * b)) + np.log(b)) * (-2.5 / np.log(10))\n",
    "\n",
    "\n",
    "# divide panstarrs fluxes and errors by 3621e-9\n",
    "\n",
    "\n",
    "def calc_ls_mags_ab(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features[\"ls_mag_g\"] = mag_ab_from_flux_nanomagies(features[\"ls_flux_g\"])\n",
    "    features[\"ls_mag_r\"] = mag_ab_from_flux_nanomagies(features[\"ls_flux_r\"])\n",
    "    features[\"ls_mag_z\"] = mag_ab_from_flux_nanomagies(features[\"ls_flux_z\"])\n",
    "    features[\"ls_mag_w1\"] = mag_ab_from_flux_nanomagies(features[\"ls_flux_w1\"])\n",
    "    features[\"ls_mag_w2\"] = mag_ab_from_flux_nanomagies(features[\"ls_flux_w2\"])\n",
    "    return features\n",
    "\n",
    "\n",
    "def calc_ls_mags(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features[\"ls_mag_g\"] = asinhmag_dm(features[\"ls_flux_g\"], flux_ivar=features[\"ls_flux_ivar_g\"])\n",
    "    features[\"ls_mag_r\"] = asinhmag_dm(features[\"ls_flux_r\"], flux_ivar=features[\"ls_flux_ivar_r\"])\n",
    "    features[\"ls_mag_z\"] = asinhmag_dm(features[\"ls_flux_z\"], flux_ivar=features[\"ls_flux_ivar_z\"])\n",
    "    features[\"ls_mag_w1\"] = asinhmag_dm(features[\"ls_flux_w1\"], flux_ivar=features[\"ls_flux_ivar_w1\"])\n",
    "    features[\"ls_mag_w2\"] = asinhmag_dm(features[\"ls_flux_w2\"], flux_ivar=features[\"ls_flux_ivar_w2\"])\n",
    "    return features\n",
    "\n",
    "\n",
    "def cals_sdss_mags_ab(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features[\"sdss_cModelMag_u\"] = mag_ab_from_flux_nanomagies(features[\"sdss_cModelFlux_u\"])\n",
    "    features[\"sdss_cModelMag_g\"] = mag_ab_from_flux_nanomagies(features[\"sdss_cModelFlux_g\"])\n",
    "    features[\"sdss_cModelMag_r\"] = mag_ab_from_flux_nanomagies(features[\"sdss_cModelFlux_r\"])\n",
    "    features[\"sdss_cModelMag_i\"] = mag_ab_from_flux_nanomagies(features[\"sdss_cModelFlux_i\"])\n",
    "    features[\"sdss_cModelMag_z\"] = mag_ab_from_flux_nanomagies(features[\"sdss_cModelFlux_z\"])\n",
    "    return features\n",
    "\n",
    "\n",
    "def cals_sdss_mags(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features[\"sdss_cModelMag_u\"] = asinhmag_dm(features[\"sdss_cModelFlux_u\"], flux_ivar=features[\"sdss_cModelFluxIvar_u\"])\n",
    "    features[\"sdss_cModelMag_g\"] = asinhmag_dm(features[\"sdss_cModelFlux_g\"], flux_ivar=features[\"sdss_cModelFluxIvar_g\"])\n",
    "    features[\"sdss_cModelMag_r\"] = asinhmag_dm(features[\"sdss_cModelFlux_r\"], flux_ivar=features[\"sdss_cModelFluxIvar_r\"])\n",
    "    features[\"sdss_cModelMag_i\"] = asinhmag_dm(features[\"sdss_cModelFlux_i\"], flux_ivar=features[\"sdss_cModelFluxIvar_i\"])\n",
    "    features[\"sdss_cModelMag_z\"] = asinhmag_dm(features[\"sdss_cModelFlux_z\"], flux_ivar=features[\"sdss_cModelFluxIvar_z\"])\n",
    "    return features\n",
    "\n",
    "\n",
    "def calc_ps_mags_ab(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features[\"ps_gKronMag\"] = mag_ab_from_flux_jy(features[\"ps_gKronFlux\"])\n",
    "    features[\"ps_rKronMag\"] = mag_ab_from_flux_jy(features[\"ps_rKronFlux\"])\n",
    "    features[\"ps_iKronMag\"] = mag_ab_from_flux_jy(features[\"ps_iKronFlux\"])\n",
    "    features[\"ps_zKronMag\"] = mag_ab_from_flux_jy(features[\"ps_zKronFlux\"])\n",
    "    features[\"ps_yKronMag\"] = mag_ab_from_flux_jy(features[\"ps_yKronFlux\"])\n",
    "    return features\n",
    "\n",
    "\n",
    "def calc_ps_mags(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features[\"ps_gKronMag\"] = asinhmag_dm(features[\"ps_gKronFlux\"] / 3621e-9, flux_err=features[\"ps_gKronFluxErr\"] / 3621e-9)\n",
    "    features[\"ps_rKronMag\"] = asinhmag_dm(features[\"ps_rKronFlux\"] / 3621e-9, flux_err=features[\"ps_rKronFluxErr\"] / 3621e-9)\n",
    "    features[\"ps_iKronMag\"] = asinhmag_dm(features[\"ps_iKronFlux\"] / 3621e-9, flux_err=features[\"ps_iKronFluxErr\"] / 3621e-9)\n",
    "    features[\"ps_zKronMag\"] = asinhmag_dm(features[\"ps_zKronFlux\"] / 3621e-9, flux_err=features[\"ps_zKronFluxErr\"] / 3621e-9)\n",
    "    features[\"ps_yKronMag\"] = asinhmag_dm(features[\"ps_yKronFlux\"] / 3621e-9, flux_err=features[\"ps_yKronFluxErr\"] / 3621e-9)\n",
    "    return features\n",
    "\n",
    "\n",
    "def calc_ls_colors(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features[\"ls_g-r_color\"] = features[\"ls_mag_g\"] - features[\"ls_mag_r\"]\n",
    "    features[\"ls_g-z_color\"] = features[\"ls_mag_g\"] - features[\"ls_mag_z\"]\n",
    "    features[\"ls_g-w1_color\"] = features[\"ls_mag_g\"] - features[\"ls_mag_w1\"]\n",
    "    features[\"ls_g-w2_color\"] = features[\"ls_mag_g\"] - features[\"ls_mag_w2\"]\n",
    "    features[\"ls_r-z_color\"] = features[\"ls_mag_r\"] - features[\"ls_mag_z\"]\n",
    "    features[\"ls_r-w1_color\"] = features[\"ls_mag_r\"] - features[\"ls_mag_w1\"]\n",
    "    features[\"ls_r-w2_color\"] = features[\"ls_mag_r\"] - features[\"ls_mag_w2\"]\n",
    "    features[\"ls_z-w1_color\"] = features[\"ls_mag_z\"] - features[\"ls_mag_w1\"]\n",
    "    features[\"ls_z-w2_color\"] = features[\"ls_mag_z\"] - features[\"ls_mag_w2\"]\n",
    "    features[\"ls_w1-w2_color\"] = features[\"ls_mag_w1\"] - features[\"ls_mag_w2\"]\n",
    "    return features\n",
    "\n",
    "\n",
    "def calc_ps_colors(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass  # TODO\n",
    "\n",
    "\n",
    "def calc_sdss_colors(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read data and rename columns\n",
    "\n",
    "def get_column_name_mapper(prefix: str):\n",
    "        return lambda column_name: f\"{prefix}_{{}}\".format(column_name)\n",
    "\n",
    "\n",
    "meta_object_data = pd.read_parquet(SRG_DATA_PATH / \"surveys_metaobject.parquet\")\n",
    "erosita_data = (\n",
    "        pd.read_parquet(SRG_DATA_PATH / \"surveys_erosita.parquet\")\n",
    "        .rename(get_column_name_mapper(\"ero\"), axis=1)\n",
    ")\n",
    "ls_data = (\n",
    "        pd.read_parquet(SRG_DATA_PATH / \"surveys_ls.parquet\")\n",
    "        .rename(get_column_name_mapper(\"ls\"), axis=1)\n",
    ")\n",
    "ps_data = (\n",
    "        pd.read_parquet(SRG_DATA_PATH / \"surveys_ps.parquet\")\n",
    "        .rename(get_column_name_mapper(\"ps\"), axis=1)\n",
    ")\n",
    "sdss_data = (\n",
    "        pd.read_parquet(SRG_DATA_PATH / \"surveys_sdss.parquet\")\n",
    "        .rename(get_column_name_mapper(\"sdss\"), axis=1)\n",
    ")\n",
    "gaia_data = (\n",
    "        pd.read_parquet(SRG_DATA_PATH / \"surveys_gaia.parquet\")\n",
    "        .rename(get_column_name_mapper(\"gaia\"), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_object_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# merge tables\n",
    "\n",
    "print(erosita_data.shape)\n",
    "erosita_data = pd.merge(left=erosita_data, right=ls_data, left_on=\"ero_ls_dup\", right_on=\"ls_id\", how=\"left\")\n",
    "erosita_data = pd.merge(left=erosita_data, right=ps_data, left_on=\"ero_ps_dup\", right_on=\"ps_id\", how=\"left\")\n",
    "erosita_data = pd.merge(left=erosita_data, right=sdss_data, left_on=\"ero_sdss_dup\", right_on=\"sdss_id\", how=\"left\")\n",
    "erosita_data = pd.merge(left=erosita_data, right=gaia_data, left_on=\"ero_gaia_dup\", right_on=\"gaia_id\", how=\"left\")\n",
    "print(erosita_data.shape)\n",
    "\n",
    "\n",
    "meta_object_to_erosita_relation = pd.read_parquet(SRG_DATA_PATH / \"surveys_erosita_meta_objects.parquet\")\n",
    "print(meta_object_to_erosita_relation.shape)\n",
    "meta_object_to_erosita_relation = pd.merge(left=meta_object_data, right=meta_object_to_erosita_relation,\n",
    "                                           left_on=\"id\", right_on=\"metaobject_id\")\n",
    "meta_object_to_erosita_relation = pd.merge(left=meta_object_to_erosita_relation, right=erosita_data,\n",
    "                                           left_on=\"erosita_id\", right_on=\"ero_id\")\n",
    "print(meta_object_to_erosita_relation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# as we do not have master survey connection, get source with max x-ray flux for every meta object\n",
    "# and save the result\n",
    "\n",
    "group_max_xflux = list()\n",
    "\n",
    "for _, group in tqdm(meta_object_to_erosita_relation.groupby(\"metaobject_id\")):\n",
    "        group = group.loc[group[\"ero_flux_05_20\"] == group[\"ero_flux_05_20\"].max()]\n",
    "        group_max_xflux.append(group)\n",
    "\n",
    "assembled_srg_data = pd.concat(group_max_xflux, axis=0)\n",
    "\n",
    "assembled_srg_data = calc_ls_mags(assembled_srg_data)\n",
    "assembled_srg_data = cals_sdss_mags(assembled_srg_data)\n",
    "assembled_srg_data = calc_ps_mags(assembled_srg_data)\n",
    "\n",
    "assembled_srg_data.to_parquet(ASSEMBLED_DATA_PATH / \"srg_data.parquet\", compression=\"GZIP\")\n",
    "assembled_srg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assembled_srg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Подготовка данных спектральных наблюдений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Чтение данных с признаками и подготовка разметки\n",
    "\n",
    "В этих данных содержатся комментарии наблюдателей, из которых класс источника нужно вычленить в отдельный столбец\n",
    "\n",
    "В первом приближении в качестве класса возьмем программу наблюдений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "triton_with_photometry_path = TRITON_DATA_PATH / \"x1a\" / \"part-00000.features.gz_pkl\"\n",
    "triton_data = pd.read_pickle(triton_with_photometry_path, compression=\"gzip\")\n",
    "triton_data = triton_data.loc[triton_data[\"Prog\"].isin(TRANSIENT_SURVEY._member_names_)]\n",
    "\n",
    "triton_data = calc_ls_mags(triton_data)\n",
    "triton_data = cals_sdss_mags(triton_data)\n",
    "triton_data = calc_ps_mags(triton_data)\n",
    "\n",
    "triton_data.to_parquet(ASSEMBLED_DATA_PATH / \"triton_data.parquet\", compression=\"GZIP\")\n",
    "\n",
    "triton_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "triton_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Анализ с кластеризацией TBD\n",
    "\n",
    "**План**\n",
    "\n",
    "Кластеризация все-равно делается перебором алгоритмов, поэтому делаем так:\n",
    "- Нагенерить фичей (можно начать с дефолтных -- величины и цвета)\n",
    "- Применить понижение размерности / feature selection.\n",
    "- Применяем кластеризации и смотрим на резальтаты в разметке <z, class>\n",
    "\n",
    "___TODO___\n",
    "\n",
    "- Нужно привести датафреймы к одинаковым названиям столбцов + чтобы это было воспроизводимо\n",
    "- Т.е. доработать предобработку\n",
    "- Есть проблема, связанная с пропусками\n",
    "- Сделать гиперболические величины\n",
    "- Исследуем на источниках, для которых есть DESI LIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "from dummy_str_enum import DummyStrEnum\n",
    "\n",
    "LS_MAG_COLUMNS = DummyStrEnum.from_list(\n",
    "    \"LS_MAG_COLUMNS\", 'ls_mag_r', 'ls_mag_g', 'ls_mag_z', 'ls_mag_w1', 'ls_mag_w2')\n",
    "LS_COLOR_COLUMNS = DummyStrEnum.from_list(\n",
    "    \"LS_COLOR_COLUMNS\",\n",
    "    'ls_color_g-r', 'ls_color_g-z', 'ls_color_g-w1', 'ls_color_g-w2',\n",
    "    'ls_color_r-z', 'ls_color_r-w1', 'ls_color_r-w2',\n",
    "    'ls_color_z-w1', 'ls_color_z-w2',\n",
    "    'ls_color_w1-w2',\n",
    ")\n",
    "\n",
    "PS_MAG_COLUMNS = DummyStrEnum.from_list(\n",
    "    \"PS_MAG_COLUMNS\", 'ps_gKronMag', 'ps_rKronMag', 'ps_iKronMag', 'ps_zKronMag', 'ps_yKronMag')\n",
    "SDSS_MAG_COLUMNS = DummyStrEnum.from_list(\n",
    "    \"SDSS_MAG_COLUMNS\", 'sdss_cModelMag_u', 'sdss_cModelMag_g', 'sdss_cModelMag_r',\n",
    "    'sdss_cModelMag_i', 'sdss_cModelMag_z')\n",
    "WISE_FORCED_MAG_COLUMNS = DummyStrEnum(\"WISE_FORCED_MAG_COLUMNS\", w1mag=\"ps_w1mag\", w2mag=\"ps_w2mag\")\n",
    "XRAY_COLUMNS = DummyStrEnum.from_list(\"XRAY_COLUMNS\", \"ln_flux_05_20\")\n",
    "\n",
    "ALL_FEATURES = LS_MAG_COLUMNS + PS_MAG_COLUMNS + SDSS_MAG_COLUMNS + WISE_FORCED_MAG_COLUMNS + XRAY_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "srg_data = pd.read_parquet(ASSEMBLED_DATA_PATH / \"srg_data.parquet\")\n",
    "srg_data[XRAY_COLUMNS.ln_flux_05_20] = np.log10(srg_data[\"ero_flux_05_20\"])\n",
    "srg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "triton_data = pd.read_parquet(ASSEMBLED_DATA_PATH / \"triton_data.parquet\")\n",
    "# triton_data[XRAY_COLUMNS.ln_flux_05_20] = np.log10(triton_data[\"ero_flux_05_20\"])\n",
    "triton_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate features\n",
    "\n",
    "def calculate_colors(data: pd.DataFrame, passbands: list[str], mag_column_template: str, color_column_template: str):\n",
    "    for pb1, pb2 in itertools.combinations(passbands, 2):\n",
    "        # print(color_column_template.format(pb1, pb2))\n",
    "        data[color_column_template.format(pb1, pb2)] = (\n",
    "                data[mag_column_template.format(pb1)] - data[mag_column_template.format(pb2)]\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_ls_colors(data: pd.DataFrame, mag_colunm_template=\"ls_mag_{}\", color_column_template=\"ls_color_{}-{}\"):\n",
    "    return calculate_colors(data, [\"g\", \"r\", \"z\", \"w1\", \"w2\"], mag_colunm_template, color_column_template)\n",
    "\n",
    "\n",
    "srg_data = calculate_ls_colors(srg_data)\n",
    "triton_data = calculate_ls_colors(triton_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nans_anal(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Analyse, how many nans are in magnitudes.\n",
    "\n",
    "    :param df:\n",
    "    :return: mask specified in result_mask variable (see code lol)\n",
    "    \"\"\"\n",
    "    df = df.replace([-np.inf, np.inf], np.nan)\n",
    "\n",
    "    notna_mask_ps = (\n",
    "            df[PS_MAG_COLUMNS.elements.values()].notna()\n",
    "            & (df[PS_MAG_COLUMNS.elements.values()] >= 0)\n",
    "    ).all(axis=1)\n",
    "    notna_mask_ls = df[LS_MAG_COLUMNS.elements.values()].notna().all(axis=1)\n",
    "    notna_mask_sdss = df[SDSS_MAG_COLUMNS.elements.values()].notna().all(axis=1)\n",
    "    notna_mask_wf = (\n",
    "            df[WISE_FORCED_MAG_COLUMNS.elements.values()].notna()\n",
    "            & (df[WISE_FORCED_MAG_COLUMNS.elements.values()] >= 0)\n",
    "    ).all(axis=1)\n",
    "\n",
    "    print(\"Total objects:\", df.shape[0])\n",
    "    print(\"Has all LS:\", notna_mask_ls.sum())\n",
    "    print(\"Has all PS:\", notna_mask_ps.sum())\n",
    "    print(\"Has all SDSS:\", notna_mask_sdss.sum())\n",
    "    print(\"Has all WISE FORCED:\", notna_mask_wf.sum())\n",
    "\n",
    "    print(\"Has all LS and PS:\", (notna_mask_ls & notna_mask_ps).sum())\n",
    "    print(\"Has all SDSS and PS:\", (notna_mask_sdss & notna_mask_ps).sum())\n",
    "    print(\"Has all LS and SDSS:\", (notna_mask_ls & notna_mask_sdss).sum())\n",
    "\n",
    "    print(\"Has all LS and PS and SDSS\", (notna_mask_ps & notna_mask_sdss & notna_mask_ls).sum())\n",
    "\n",
    "    result_mask = notna_mask_ls\n",
    "    print(result_mask.sum())\n",
    "    return result_mask\n",
    "\n",
    "\n",
    "print(\"SRG Data:\")\n",
    "srg_data = srg_data.loc[nans_anal(srg_data)]\n",
    "print(\"\\n\\nTriton Data:\")\n",
    "triton_data = triton_data.loc[nans_anal(triton_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Expert features by mesch\n",
    "EXPERT_FEATURES_LIST = ['ls_star_zw2_rz_score', 'ls_X/w1_h', 'ls_Fx/Fz']\n",
    "\n",
    "\n",
    "def calculate_expert_features_with_fx(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Вычисление экспертных признаков, хорошо разделяющих\n",
    "    спектральные классы источников (звезды и квазары, галактики)\n",
    "    по фотометрии DESI LIS и рентгеновскому потоку 0.5--2.0 кэв.\n",
    "\n",
    "    Признаки:\n",
    "    - ls_X/w1_h = (w1 - 2.699) - (-1.625 * lgFx - 8.8)\n",
    "    - ls_Fx/Fz = z - (-2.5 * lgFx - 18)\n",
    "\n",
    "    :param df: датафрейм с величинами\n",
    "    :return: исходный датафрейм с добавленными признаками\n",
    "    \"\"\"\n",
    "\n",
    "    Preconditions.check(\"ero_flux_05_20\" in df.columns, \"There must be ero_flux_05_20 column\")\n",
    "    Preconditions.check(\"ls_mag_w1\" in df.columns, \"There must be ls_mag_w1 column\")\n",
    "    Preconditions.check(\"ls_mag_z\" in df.columns, \"There must be ls_mag_z column\")\n",
    "\n",
    "    df['lg(Fx)'] = np.log10(df['ero_flux_05_20'])\n",
    "    df['ls_X/w1_h']= (df['ls_mag_w1'] - 2.699) - (-1.625 * df['lg(Fx)'] - 8.8)\n",
    "\n",
    "    df['-2.5lg(Fx)-18'] = -2.5*df['lg(Fx)'] - 18\n",
    "    df['ls_Fx/Fz'] = df['ls_mag_z'] - df['-2.5lg(Fx)-18']\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_expert_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Вычисление экспертных признаков, хорошо разделяющих\n",
    "    спектральные классы источников (звезды и квазары, галактики)\n",
    "    по фотометрии DESI LIS.\n",
    "\n",
    "    Признаки:\n",
    "    - ls_star_zw2_rz_score = z-w1 - (0.4 * r-z - 1.35)\n",
    "\n",
    "    :param df: датафрейм с величинами\n",
    "    :return: исходный датафрейм с добавленными признаками\n",
    "    \"\"\"\n",
    "\n",
    "    Preconditions.check(\"ls_color_z-w2\" in df.columns, \"There must be ls_color_z-w2 column\")\n",
    "    Preconditions.check(\"ls_color_r-z\" in df.columns, \"There must be ls_color_r-z column\")\n",
    "\n",
    "    a_zw2_rz = 0.40\n",
    "    b_zw2_rz = -1.35\n",
    "    df['ls_star_zw2_rz_score'] = df[\"ls_color_z-w2\"] - (a_zw2_rz*(df['ls_color_r-z']) + b_zw2_rz)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "srg_data = calculate_expert_features_with_fx(srg_data)\n",
    "srg_data = calculate_expert_features(srg_data)\n",
    "triton_data = calculate_expert_features(triton_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Графики с экспертными признаками и разделяющими плоскостями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clustering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_array = srg_data[EXPERT_FEATURES_LIST + list((LS_MAG_COLUMNS).elements.values()) + [XRAY_COLUMNS.ln_flux_05_20]]\n",
    "features_array = StandardScaler().fit_transform(features_array)\n",
    "\n",
    "labels = KMeans(n_clusters=6, algorithm=\"full\").fit_predict(features_array)\n",
    "srg_data[\"clust_id\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=features_array.shape[1]).fit(features_array)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Y: 'ls_Fx/Fz'\n",
    "# X: 'decals8tr_Lw1-Lw2'\n",
    "\n",
    "def line3lin(_x:np.array, _x1:float, _y1:float, _x2:float, _y2:float, _a1:float, _a2:float, _a3:float) -> np.array:\n",
    "    '''\n",
    "    Line\n",
    "    x: np.array\n",
    "    x<=x1 : y=a1*x + (y - a1*x)\n",
    "    x> x1 : y=a2*x + (y - a1*x)\n",
    "    '''\n",
    "    _b1 = _y1 - _a1*_x1\n",
    "    _b2 = _y1 - _a2*_x1\n",
    "    _b3 = _y2 - _a3*_x2\n",
    "\n",
    "    _y = _a1*_x + _b1\n",
    "    _y[_x>_x1] =_a2*_x[_x>_x1] + _b2\n",
    "    _y[_x>_x2] =_a3*_x[_x>_x2] + _b3\n",
    "\n",
    "    return _y\n",
    "\n",
    "\n",
    "def chart3lin(df: pd.DataFrame, *, labels: ArrayOrSeries = None,\n",
    "              label_colors: list[str] = None, cmap=\"rainbow\", marker_size=1, **axes_kws):\n",
    "    x1=-0.7; y1=3; x2=0.3; y2=-1; a1=0; a2=-4; a3=0\n",
    "    x = np.arange(-3,3,0.1)\n",
    "    y = line3lin(x, x1, y1, x2, y2, a1, a2, a3)\n",
    "\n",
    "    Preconditions.check_pre(\n",
    "        labels is not None and label_colors is not None,\n",
    "        labels is not None and label_colors is not None and np.unique(labels).shape[0] == len(label_colors),\n",
    "        \"Number of label colors must be equal to number of labels\"\n",
    "    )\n",
    "\n",
    "    markers = itertools.cycle([\"x\", \"+\", \".\", \"v\", \"^\"])\n",
    "\n",
    "    if labels is None:\n",
    "        labels = np.zeros(df.shape[0])\n",
    "        unique_labels = [0]\n",
    "        label_colors = [\"blue\"]\n",
    "    else:\n",
    "        unique_labels = np.unique(labels)\n",
    "        if label_colors is None:\n",
    "            cmap = mpl.cm.get_cmap(cmap)\n",
    "            label_colors = [cmap(koef) for koef in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(17, 10))\n",
    "\n",
    "    for label, label_color in zip(unique_labels, label_colors):\n",
    "        row_indices = np.where(labels == label)\n",
    "        df_l = df.iloc[row_indices]\n",
    "        marker = next(markers)\n",
    "        ax.scatter(df_l[\"ls_color_w1-w2\"], df_l['ls_Fx/Fz'], s=marker_size, color=label_color, marker=marker)\n",
    "\n",
    "    ax.plot(x, y, ls=\"--\", color=\"black\")\n",
    "    ax.set(xlabel=\"decals8tr_Lw1-Lw2\", ylabel=\"ls_Fx/Fz\")\n",
    "    ax.set(**axes_kws)\n",
    "    ax.grid(ls=\":\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "chart3lin(srg_data, labels=labels,\n",
    "          xlim=(-2, 2), ylim=(-9, 9), marker_size=6)\n",
    "chart3lin(srg_data, labels=labels,\n",
    "          xlim=(-5, 5), ylim=(-10, 15), xticks=np.linspace(-5, 5, 21), yticks=np.linspace(-10, 14, 13), title=\"Full\", marker_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X: 'ls_star_zw2_rz_score'\n",
    "# Y: 'ls_X/w1_h'\n",
    "\n",
    "def line2lin(_x:np.array, _x1:float, _y1:float, _a1:float, _a2:float) -> np.array:\n",
    "    '''\n",
    "    Line\n",
    "    x: np.array\n",
    "    x<=x1 : y=a1*x + (y - a1*x)\n",
    "    x> x1 : y=a2*x + (y - a1*x)\n",
    "    '''\n",
    "    _b1 = _y1 - _a1*_x1\n",
    "    _b2 = _y1 - _a2*_x1\n",
    "\n",
    "    _y = _a1*_x + _b1\n",
    "    _y[_x>_x1] =_a2*_x[_x>_x1] + _b2\n",
    "\n",
    "    return _y\n",
    "\n",
    "\n",
    "def chart2lin(df: pd.DataFrame, *, labels: ArrayOrSeries = None,\n",
    "              label_colors: list[str] = None, cmap=\"rainbow\", marker_size=1, **axes_kws):\n",
    "    x1=0.6; y1=-0.2; a1=-100; a2=-0.25\n",
    "    x = np.arange(0,10,0.1)\n",
    "    y = line2lin(x, x1, y1, a1, a2)\n",
    "\n",
    "    Preconditions.check_pre(\n",
    "        labels is not None and label_colors is not None,\n",
    "        labels is not None and label_colors is not None and np.unique(labels).shape[0] == len(label_colors),\n",
    "        \"Number of label colors must be equal to number of labels\"\n",
    "    )\n",
    "\n",
    "    markers = itertools.cycle([\"x\", \"+\", \".\", \"v\", \"^\"])\n",
    "\n",
    "    if labels is None:\n",
    "        labels = np.zeros(df.shape[0])\n",
    "        unique_labels = [0]\n",
    "        label_colors = [\"blue\"]\n",
    "    else:\n",
    "        unique_labels = np.unique(labels)\n",
    "        if label_colors is None:\n",
    "            cmap = mpl.cm.get_cmap(cmap)\n",
    "            label_colors = [cmap(koef) for koef in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(17, 10))\n",
    "\n",
    "    for label, label_color in zip(unique_labels, label_colors):\n",
    "        row_indices = np.where(labels == label)\n",
    "        df_l = df.iloc[row_indices]\n",
    "        marker = next(markers)\n",
    "        ax.scatter(df_l['ls_star_zw2_rz_score'], df_l['ls_X/w1_h'], s=marker_size, color=label_color, marker=marker)\n",
    "\n",
    "    ax.plot(x, y, ls=\"--\", color=\"black\")\n",
    "    ax.set(xlabel='ls_star_zw2_rz_score', ylabel='ls_X/w1_h')\n",
    "    ax.set(**axes_kws)\n",
    "    ax.grid(ls=\":\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "chart2lin(srg_data, labels=labels, xlim=(-4, 10), ylim=(-9, 9), marker_size=6)\n",
    "chart2lin(srg_data, labels=labels, xlim=(-4, 10), ylim=(-9, 15), yticks=np.linspace(-8, 14, 12), title=\"Full\", marker_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# KDE plots\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "def calculate_kde(x: ArrayOrSeries, y: ArrayOrSeries, *,\n",
    "             xlim: tuple[float, float], ylim: tuple[float, float], grid_step: float = 0.1\n",
    "             ) -> (np.array, np.array, np.array):\n",
    "    xmin, xmax = xlim\n",
    "    ymin, ymax = ylim\n",
    "    xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = st.gaussian_kde(values)\n",
    "    f = np.reshape(kernel(positions).T, xx.shape)\n",
    "    return xx, yy, f\n",
    "\n",
    "\n",
    "def CustomCmap(from_rgba,to_rgba):\n",
    "    r1,g1,b1,_ = from_rgba\n",
    "    r2,g2,b2,_ = to_rgba\n",
    "    cdict = {'red': ((0, r1, r1),\n",
    "                     (1, r2, r2)),\n",
    "             'green': ((0, g1, g1),\n",
    "                       (1, g2, g2)),\n",
    "             'blue': ((0, b1, b1),\n",
    "                      (1, b2, b2))}\n",
    "\n",
    "    cmap = mpl.colors.LinearSegmentedColormap('custom_cmap', cdict)\n",
    "    return cmap\n",
    "\n",
    "\n",
    "def chart_lin_kde(df: pd.DataFrame, xcol: str, ycol: str, line: Optional[tuple[np.array, np.array]], *,\n",
    "                  nrowscols: tuple[int, int], xlim: tuple[int, int], ylim: tuple[int, int], axsize=(5, 5),\n",
    "                  labels: ArrayOrSeries = None, label_colors: list[str] = None, cmap=\"rainbow\", marker_size=1, **axes_kws):\n",
    "\n",
    "    Preconditions.check_pre(\n",
    "        labels is not None and label_colors is not None,\n",
    "        labels is not None and label_colors is not None and np.unique(labels).shape[0] == len(label_colors),\n",
    "        \"Number of label colors must be equal to number of labels\"\n",
    "    )\n",
    "\n",
    "    print(f\"Hint: xcol={xcol}\\t min={df[xcol].min():.5f}\\t max={df[xcol].max():.5f}\")\n",
    "    print(f\"Hint: ycol={ycol}\\t min={df[ycol].min():.5f}\\t max={df[ycol].max():.5f}\")\n",
    "\n",
    "    if labels is None:\n",
    "        labels = np.zeros(df.shape[0])\n",
    "        unique_labels = [0]\n",
    "        label_colors = [\"blue\"]\n",
    "    else:\n",
    "        unique_labels = np.unique(labels)\n",
    "        if label_colors is None:\n",
    "            cmap = mpl.cm.get_cmap(cmap)\n",
    "            label_colors = [cmap(koef) for koef in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "    Preconditions.check(nrowscols[0] * nrowscols[1] >= len(unique_labels), \"Not enough axes!\")\n",
    "\n",
    "    fig, axs = plt.subplots(nrowscols[0], nrowscols[1], figsize=(axsize[1] * nrowscols[1], axsize[0] * nrowscols[0]))\n",
    "\n",
    "    clusters_kdes = dict()\n",
    "\n",
    "    for ax_i in range(len(unique_labels)):\n",
    "        ax = axs.flat[ax_i]\n",
    "        for cluster_i, (label, label_color) in enumerate(zip(unique_labels, label_colors)):\n",
    "            row_indices = np.where(labels == label)\n",
    "            df_l = df.iloc[row_indices]\n",
    "\n",
    "            if ax_i == cluster_i:\n",
    "                marker = \".\"\n",
    "                ax.scatter(df_l[xcol], df_l[ycol], s=marker_size, color=label_color, marker=marker, label=f\"Cluster No. {label}\")\n",
    "                ax.legend()\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                kde = clusters_kdes[label]\n",
    "            except KeyError:\n",
    "                kde = calculate_kde(df_l[xcol], df_l[ycol], xlim=xlim, ylim=ylim)\n",
    "                clusters_kdes[label] = kde\n",
    "\n",
    "            cset = ax.contour(*kde, levels=[0.01, 0.05, 0.1, 0.2, 0.5],cmap=CustomCmap(label_color, label_color), linewidths=1)\n",
    "            ax.clabel(cset, inline=1, fontsize=10)\n",
    "\n",
    "        if line is not None:\n",
    "            ax.plot(*line, ls=\"--\", color=\"black\")\n",
    "\n",
    "        ax.set(xlabel=xcol, ylabel=ycol)\n",
    "        ax.set(xlim=xlim, ylim=ylim, **axes_kws)\n",
    "        ax.grid(ls=\":\")\n",
    "\n",
    "    for i, axs_row in enumerate(axs):\n",
    "        for j, ax in enumerate(axs_row):\n",
    "            if i < axs.shape[0] - 1:\n",
    "                ax.set(xticklabels=[], xlabel=\"\")\n",
    "\n",
    "            if j > 0:\n",
    "                ax.set(yticklabels=[], ylabel=\"\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x1=-0.7; y1=3; x2=0.3; y2=-1; a1=0; a2=-4; a3=0\n",
    "x = np.arange(-3,3,0.1)\n",
    "y = line3lin(x, x1, y1, x2, y2, a1, a2, a3)\n",
    "\n",
    "chart_lin_kde(srg_data, \"ls_color_w1-w2\", 'ls_Fx/Fz', (x, y),\n",
    "              labels=labels, nrowscols=(2, 3), xlim=(-4, 4), ylim=(-9, 15), yticks=np.linspace(-8, 14, 12), marker_size=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x1=0.6; y1=-0.2; a1=-100; a2=-0.25\n",
    "x = np.arange(0,10,0.1)\n",
    "y = line2lin(x, x1, y1, a1, a2)\n",
    "\n",
    "chart_lin_kde(srg_data, 'ls_star_zw2_rz_score', 'ls_X/w1_h', (x, y),\n",
    "              labels=labels, nrowscols=(2, 3), xlim=(-4, 10), ylim=(-9, 15), yticks=np.linspace(-8, 14, 12), marker_size=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chart_lin_kde(srg_data, 'ls_mag_g', 'ls_mag_w1', None,\n",
    "              labels=labels, nrowscols=(2, 3), xlim=(5, 30), ylim=(5, 30), marker_size=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chart_lin_kde(srg_data, 'ls_color_w1-w2', 'ls_color_g-z', None,\n",
    "              labels=labels, nrowscols=(2, 3), xlim=(-3, 3), ylim=(-4, 5), marker_size=4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Последовательное сравнение алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, MeanShift, SpectralClustering, DBSCAN, OPTICS\n",
    "from tqdm.auto import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def line2lin(_x:np.array, _x1:float, _y1:float, _a1:float, _a2:float) -> np.array:\n",
    "    '''\n",
    "    Line\n",
    "    x: np.array\n",
    "    x<=x1 : y=a1*x + (y - a1*x)\n",
    "    x> x1 : y=a2*x + (y - a1*x)\n",
    "    '''\n",
    "    _b1 = _y1 - _a1*_x1\n",
    "    _b2 = _y1 - _a2*_x1\n",
    "\n",
    "    _y = _a1*_x + _b1\n",
    "    _y[_x>_x1] =_a2*_x[_x>_x1] + _b2\n",
    "\n",
    "    return _y\n",
    "\n",
    "\n",
    "def line3lin(_x:np.array, _x1:float, _y1:float, _x2:float, _y2:float, _a1:float, _a2:float, _a3:float) -> np.array:\n",
    "    '''\n",
    "    Line\n",
    "    x: np.array\n",
    "    x<=x1 : y=a1*x + (y - a1*x)\n",
    "    x> x1 : y=a2*x + (y - a1*x)\n",
    "    '''\n",
    "    _b1 = _y1 - _a1*_x1\n",
    "    _b2 = _y1 - _a2*_x1\n",
    "    _b3 = _y2 - _a3*_x2\n",
    "\n",
    "    _y = _a1*_x + _b1\n",
    "    _y[_x>_x1] =_a2*_x[_x>_x1] + _b2\n",
    "    _y[_x>_x2] =_a3*_x[_x>_x2] + _b3\n",
    "\n",
    "    return _y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "DRAW = True\n",
    "CHARTS_PATH = Path(f\"charts\") / f\"{datetime.now().strftime('%Y-%m-%d %H-%M-%S')}\"\n",
    "\n",
    "features_array = srg_data[EXPERT_FEATURES_LIST + list((LS_MAG_COLUMNS).elements.values()) + [XRAY_COLUMNS.ln_flux_05_20]]\n",
    "features_array = StandardScaler().fit_transform(features_array)\n",
    "\n",
    "nrowscols=(2, 4)\n",
    "\n",
    "models = [\n",
    "    KMeans(n_clusters=4, algorithm=\"full\"),\n",
    "    KMeans(n_clusters=6, algorithm=\"full\"),\n",
    "    KMeans(n_clusters=8, algorithm=\"full\"),\n",
    "    DBSCAN(),\n",
    "]\n",
    "\n",
    "for i, model in tqdm(enumerate(models)):\n",
    "    print(f\"=== {i}\\t{model} ===\")\n",
    "\n",
    "    MODEL_CHARTS_PATH = CHARTS_PATH / f\"{i:02d}\"\n",
    "    os.makedirs(MODEL_CHARTS_PATH)\n",
    "\n",
    "    with open(MODEL_CHARTS_PATH / \"model_description.txt\", \"w\") as fout:\n",
    "        fout.write(f\"{model}\\n{model.__class__.__name__}\\n{model.get_params()}\")\n",
    "\n",
    "    labels = model.fit_predict(features_array)\n",
    "    number_of_labels = np.unique(labels).shape[0]\n",
    "    nrowscols = (number_of_labels // 4 + 1, 4)\n",
    "    print(nrowscols)\n",
    "\n",
    "    if not DRAW:\n",
    "        continue\n",
    "\n",
    "    x1=-0.7; y1=3; x2=0.3; y2=-1; a1=0; a2=-4; a3=0\n",
    "    x = np.arange(-3,3,0.1)\n",
    "    y = line3lin(x, x1, y1, x2, y2, a1, a2, a3)\n",
    "\n",
    "    xcol, ycol = \"ls_color_w1-w2\", 'ls_Fx/Fz'\n",
    "    FILENAME = f\"{xcol}-x-{ycol}.png\".replace(\"/\", \"\").replace(\":\", \"\")\n",
    "    fig = chart_lin_kde(srg_data, xcol, ycol, (x, y),\n",
    "                  labels=labels, nrowscols=nrowscols, xlim=(-4, 4), ylim=(-9, 15), yticks=np.linspace(-8, 14, 12), marker_size=4)\n",
    "    fig.savefig(MODEL_CHARTS_PATH / FILENAME)\n",
    "    plt.close()\n",
    "\n",
    "    x1=0.6; y1=-0.2; a1=-100; a2=-0.25\n",
    "    x = np.arange(0,10,0.1)\n",
    "    y = line2lin(x, x1, y1, a1, a2)\n",
    "\n",
    "    xcol, ycol = 'ls_star_zw2_rz_score', 'ls_X/w1_h'\n",
    "    FILENAME = f\"{xcol}-x-{ycol}.png\".replace(\"/\", \"\").replace(\":\", \"\")\n",
    "    fig = chart_lin_kde(srg_data, xcol, ycol, (x, y),\n",
    "              labels=labels, nrowscols=nrowscols, xlim=(-4, 10), ylim=(-9, 15), yticks=np.linspace(-8, 14, 12), marker_size=4)\n",
    "    fig.savefig(MODEL_CHARTS_PATH / FILENAME)\n",
    "    plt.close()\n",
    "\n",
    "    xcol, ycol = 'ls_mag_g', 'ls_mag_w1'\n",
    "    FILENAME = f\"{xcol}-x-{ycol}.png\".replace(\"/\", \"\").replace(\":\", \"\")\n",
    "    fig = chart_lin_kde(srg_data, xcol, ycol, None,\n",
    "                        labels=labels, nrowscols=nrowscols, xlim=(5, 30), ylim=(5, 30), marker_size=4)\n",
    "    fig.savefig(MODEL_CHARTS_PATH / FILENAME)\n",
    "    plt.close()\n",
    "\n",
    "    xcol, ycol = 'ls_color_w1-w2', 'ls_color_g-z'\n",
    "    FILENAME = f\"{xcol}-x-{ycol}.png\".replace(\"/\", \"\").replace(\":\", \"\")\n",
    "    fig = chart_lin_kde(srg_data, xcol, ycol, None,\n",
    "                        labels=labels, nrowscols=nrowscols, xlim=(-3, 3), ylim=(-4, 5), marker_size=4)\n",
    "    fig.savefig(MODEL_CHARTS_PATH / FILENAME)\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}